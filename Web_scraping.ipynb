{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75add974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bf\n",
    "import traceback\n",
    "import time\n",
    "\n",
    "def states(main_url):\n",
    "    main_url = str(main_url)\n",
    "    r = requests.get(main_url)\n",
    "\n",
    "    soup = bf(r.content, 'html.parser')\n",
    "    anchors = soup.find_all(\"a\")\n",
    "\n",
    "    all_lnks = set()\n",
    "    for link in anchors:\n",
    "        if link!= '#':\n",
    "            link = link.get('href')\n",
    "            if \"policy\" not in link and \"https\" not in link and \"#\" not in link:\n",
    "\n",
    "                all_lnks.add(\"https://www.quicktransportsolutions.com/carrier/\"+link)\n",
    "    for i in list(all_lnks):\n",
    "\n",
    "        folder_name = f\"{i.split('/')[-2]}_{i.split('/')[-1].split('.')[0]}\"\n",
    "\n",
    "        if not os.path.exists(os.path.join(os.getcwd(), folder_name)):\n",
    "            os.makedirs(folder_name)\n",
    "    return list(all_lnks)\n",
    "\n",
    "\n",
    "def get_cities(sub_url_1):\n",
    "    sub_url_1 = sub_url_1\n",
    "    r = requests.get(sub_url_1)\n",
    "    \n",
    "    soup = bf(r.content, 'html.parser')\n",
    "    anchors = soup.find_all(\"a\")\n",
    "    #     print(anchors)\n",
    "    all_lnks = set()\n",
    "    for link in anchors:\n",
    "        link = link.get('href')\n",
    "\n",
    "        if link != None:\n",
    "\n",
    "            if \"#\" not in link and \"policy\" not in link and \"https\" not in link and \"index\" not in link and \"carrier\" not in link:\n",
    "                if len((sub_url_1.split('/'))) == 6:\n",
    "\n",
    "\n",
    "\n",
    "                    all_lnks.add(\"https://www.quicktransportsolutions.com/carrier/\"+sub_url_1.split(\"/\")[-2]+\"/\"+link)\n",
    "                else:\n",
    "                    all_lnks.add(\"https://www.quicktransportsolutions.com/carrier/\"+sub_url_1.split(\"/\")[-3]+\"/\"+sub_url_1.split(\"/\")[-2]+\"/\"+link)\n",
    "\n",
    "\n",
    "\n",
    "    return list(all_lnks)\n",
    "def cities(url):\n",
    "    title = []\n",
    "    address = []\n",
    "    phone = []\n",
    "    other_add = []\n",
    "    USDOT_list = []\n",
    "    tr = []\n",
    "    saad = 0\n",
    "    j = url\n",
    "    i = 2\n",
    "    flag = True\n",
    "#     for new in range(2,70):\n",
    "    while flag:\n",
    "        \n",
    "        if saad == 0:\n",
    "            r = requests.get(url)\n",
    "            saad+=1\n",
    "        else:\n",
    "            url = f'{j}?page={i}\"'\n",
    "            i+=1\n",
    "            \n",
    "            \n",
    "        \n",
    "        r = requests.get(url)\n",
    "        \n",
    "\n",
    "        soup = bf(r.content, 'html.parser')\n",
    "\n",
    "        #name\n",
    "        name_tag = soup.find_all(\"span\", itemprop=\"name\")\n",
    "\n",
    "        for name in name_tag:\n",
    "            if name.b != None:\n",
    "                title.append(name.b.text)\n",
    "\n",
    "    #     streetAddress\n",
    "\n",
    "        streetAddress = soup.find_all(\"span\", itemprop=\"streetAddress\")\n",
    "#         print(len(streetAddress))\n",
    "        if len(streetAddress) == 0:\n",
    "            flag = False\n",
    "            print(\"This URL has been traversed\")\n",
    "            continue\n",
    "\n",
    "        for street in streetAddress:\n",
    "            address.append(street.text)\n",
    "\n",
    "        phone_tag = soup.find_all('div', {'itemtype': 'https://schema.org/Organization'})\n",
    "\n",
    "        for k in phone_tag:\n",
    "            phone_elem = k.find('b', {'itemprop': 'telephone'})\n",
    "            if phone_elem is not None:\n",
    "                phone_number = phone_elem.text.strip()\n",
    "                phone.append(phone_number)\n",
    "            else:\n",
    "                phone.append(\"None\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        regtag = soup.find_all(\"span\", itemprop=\"addressRegion\")\n",
    "        addressLocality = soup.find_all(\"span\", itemprop=\"addressLocality\")\n",
    "        postalCode = soup.find_all(\"span\", itemprop=\"postalCode\")\n",
    "        trucks = soup(text=lambda t: \"Trucks\" in t.text)\n",
    "\n",
    "\n",
    "\n",
    "        for reg,add, pos in zip(regtag, addressLocality, postalCode):\n",
    "            other_add.append(f\"{reg.text}, {add.text} {pos.text}\")\n",
    "\n",
    "    #     USDOT\n",
    "\n",
    "        for USDOT in soup(text=lambda t: \"USDOT\" in t.text):\n",
    "\n",
    "            USDOT_list.append(f\"{USDOT.text} {USDOT.next_element.text}\")\n",
    "\n",
    "        #Trucs\n",
    "        trucks = soup(text=lambda t: \"Trucks\" in t.text)\n",
    "\n",
    "\n",
    "        for t in trucks:\n",
    "            tr.append(t)\n",
    "\n",
    "#         print(len(title), len(address), len(phone), len(other_add), len(tr), len(USDOT_list))\n",
    "\n",
    "    return title, address, phone, other_add, tr, USDOT_list\n",
    "\n",
    "\n",
    "def write_file(title, address, x, other_add, y, USDOT_list, file_name, j):\n",
    "    \n",
    "    \n",
    "#     if len(title) == len(address) == len(x[:-1]) ==len(other_add) ==len(y[:-1]) ==len(USDOT_list):\n",
    "        \n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df[\"Name\"] = title\n",
    "    df[\"Address\"] = address\n",
    "    df[\"Phone\"] = x\n",
    "    df[\"other_add\"] = other_add\n",
    "#   df[\"Truck_Driver\"] = y[:-1]\n",
    "    df[\"USDOT\"] = USDOT_list\n",
    "\n",
    "    df.to_excel(f\"{file_name}.xlsx\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb344af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in states(main_url):\n",
    "    folder_name = f\"{i.split('/')[-2]}_{i.split('/')[-1].split('.')[0]}\"\n",
    "\n",
    "    for j in get_cities(i):\n",
    "        print(j)\n",
    "\n",
    "        sub_folder = f\"{j.split('/')[-1].split('.')[0]}\"\n",
    "        if not os.path.exists(os.path.join(os.getcwd(),folder_name, sub_folder)):\n",
    "            os.makedirs(f\"{folder_name}/{sub_folder}\")\n",
    "        file_name = f\"{os.getcwd()}/{folder_name}/{sub_folder}/{sub_folder}\"\n",
    "        if os.path.exists(file_name):\n",
    "            print(\"The file already exist: \", file_name)\n",
    "            continue\n",
    "\n",
    "\n",
    "        \n",
    "        try:\n",
    "            if cities(j) != None:  \n",
    "                title, address, x, other_add, tr, USDOT_list = cities(j)\n",
    "                \n",
    "                \n",
    "                write_file(title, address, x, other_add, tr, USDOT_list, file_name,j)\n",
    "        except:\n",
    "            print(traceback.print_exc())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
